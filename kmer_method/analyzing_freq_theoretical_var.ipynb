{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the begginig a bit preprocessing of data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Bio as bio\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csv_data_math/CLMD_trachomatis.csv',\n",
       " 'csv_data_math/CLOS_difficile.csv',\n",
       " 'csv_data_math/CMV_AD169.csv',\n",
       " 'csv_data_math/CPBT_jejuni.csv',\n",
       " 'csv_data_math/EBV_AG876.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = [f for f in listdir('csv_data_math') if isfile(join('csv_data_math', f))]\n",
    "for i in range(len(csv_files)):\n",
    "    csv_files[i] = 'csv_data_math/' + csv_files[i]\n",
    "    \n",
    "csv_files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Proteins_data = pd.read_csv(csv_files.pop(0),  index_col=0)\n",
    "#Proteins_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in csv_files:\n",
    "    res_data = pd.read_csv(x,  index_col=0)\n",
    "    Proteins_data = pd.concat([Proteins_data, res_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106549, 402)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Proteins_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67834601,  0.70445678, -0.71153675,  4.95243735,  0.70445678,\n",
       "       -0.71153675,  2.1204503 , -0.71153675,  0.70445678,  0.70445678,\n",
       "        0.70445678, -0.71153675, -0.71153675, -0.71153675, -0.71153675,\n",
       "       -0.71153675, -0.71153675, -0.71153675,  0.70445678, -0.71153675])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be careful with your data\n",
    "\n",
    "Data_anal = Proteins_data\n",
    "\n",
    "labels_categorized = Data_anal[Data_anal.columns[0]].values\n",
    "feature_matrix = Data_anal[Data_anal.columns[2:22]].values\n",
    "\n",
    "feature_matrix[0]\n",
    "\n",
    "# Oh gosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making labels not categorized (slightly)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for x in labels_categorized:\n",
    "    if x == 'human_proteome':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "Data_anal['Label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here is the place for your code!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to make base-line with easy methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKlearn magic\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making 2 Train-Test split\n",
    "# One (final_test_*) for the final test and second (test_*) for train-test\n",
    "\n",
    "train_feature_matrix, test_feature_matrix,\\\n",
    "train_labels, test_labels = train_test_split(feature_matrix, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t h e r e  i s  n o t h i n g  i n t e r e s t i n g\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "# We will just give it try\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#train_feature_matrix_scaled = scaler.fit_transform(train_feature_matrix)\n",
    "#test_feature_matrix_scaled = scaler.fit_transform(test_feature_matrix)\n",
    "print('t h e r e  i s  n o t h i n g  i n t e r e s t i n g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try Random Forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5000, max_depth=15, \\\n",
    "                                max_features='sqrt', bootstrap='True', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap='True', class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training \n",
    "forest.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203190990145471"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score for final_test\n",
    "\n",
    "forest.score(test_feature_matrix, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.50      0.63      6330\n",
      "           1       0.82      0.95      0.88     14980\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     21310\n",
      "   macro avg       0.82      0.73      0.75     21310\n",
      "weighted avg       0.82      0.82      0.81     21310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Raw code\n",
    "\n",
    "parametrs = {'n_estimators':np.arange(4000, 6001, 1000)}\n",
    "\n",
    "gs_forest = GridSearchCV(forest, parametrs, cv = 5, scoring = 'accuracy', n_jobs=-1)\n",
    "\n",
    "gs_forest.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gs_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making LogRes class\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=30000, solver='lbfgs', tol=0.00001, penalty ='l2',\n",
    "                            C=1, class_weight = { 1 : 1 , 0: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting not preproccesed data\n",
    "\n",
    "lr_clf.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "\n",
    "lr_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score for test (Accuracy and F1-score)\n",
    "\n",
    "accuracy_log = lr_clf.score(test_feature_matrix, test_labels)\n",
    "\n",
    "prediction = lr_clf.predict(test_feature_matrix)\n",
    "\n",
    "f_1 = f1_score(prediction, test_labels)\n",
    "\n",
    "print('Acuracy = '+str(accuracy_log))\n",
    "print('F1 score  = '+str(f_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', max_iter=20000, tol=0.0001, C=1.5, gamma=2)\n",
    "\n",
    "parametrs_rbf = {'C':np.linspace(1, 20, 5), 'gamma':np.linspace(0, 10, 5)}\n",
    "\n",
    "#grid_search_rbf = GridSearchCV(svm_rbf, parametrs_rbf, cv = 5, scoring = 'accuracy', n_jobs=-1)\n",
    "#grid_search_rbf.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting not preproccesed data\n",
    "\n",
    "svm_rbf.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for test (Accuracy and F1-score)\n",
    "\n",
    "svm_rbf.score(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf.score(test_feature_matrix, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 4: Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making\n",
    "\n",
    "Gradboost = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    n_estimators=1000,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting not preproccesed data\n",
    "\n",
    "Gradboost.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy = 0.796245893946504\n",
      "F1 score  = 0.8589527027027027\n"
     ]
    }
   ],
   "source": [
    "# Score for test (Accuracy and F1-score)\n",
    "\n",
    "accuracy_log = Gradboost.score(test_feature_matrix, test_labels)\n",
    "\n",
    "prediction = Gradboost.predict(test_feature_matrix)\n",
    "\n",
    "f_1 = f1_score(prediction, test_labels)\n",
    "\n",
    "print('Acuracy = '+str(accuracy_log))\n",
    "print('F1 score  = '+str(f_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63      6330\n",
      "           1       0.84      0.88      0.86     14980\n",
      "\n",
      "   micro avg       0.80      0.80      0.80     21310\n",
      "   macro avg       0.76      0.74      0.75     21310\n",
      "weighted avg       0.79      0.80      0.79     21310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, prediction, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
