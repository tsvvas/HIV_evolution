{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from joblib import dump, load\n",
    "import urllib3\n",
    "import certifi\n",
    "from Bio import SeqIO\n",
    "import Bio\n",
    "from glob import glob\n",
    "import json\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HIV genome](https://upload.wikimedia.org/wikipedia/commons/c/c6/HIV-genome.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [\"p{}\".format(i) for i in range(1,12)]\n",
    "hiv_regions = [\"V3\", \"PR\", \"psi\", \"vpr\", \"vpu\", \"p1\", \"p2\", \"p6\", \"p7\", \"p15\", \"p17\", \"RRE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HIV genome details](https://res.mdpi.com/viruses/viruses-08-00248/article_deploy/html/images/viruses-08-00248-g002.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hivevo_haplotype(patient, hiv_region, folder):\n",
    "    \n",
    "    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',\n",
    "                               ca_certs=certifi.where())\n",
    "    \n",
    "    api = \"https://hiv.biozentrum.unibas.ch/api/data/haplotypes/\"\n",
    "    \n",
    "    url = \"/\".join((api, patient, hiv_region))\n",
    "\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    file_name = folder + \"_\".join((\"hivevo\", patient, region)) + \".fasta\"\n",
    "\n",
    "    with http.request('GET', url, preload_content=False) as res, open(file_name, 'wb') as out_file:\n",
    "\n",
    "        shutil.copyfileobj(res, out_file)\n",
    "        \n",
    "folder = \"data/\"\n",
    "for patient in patients:\n",
    "    for region in hiv_regions:\n",
    "        download_hivevo_haplotype(patient, region, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hivevo_references(folder):\n",
    "    global patients    \n",
    "    \n",
    "    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',\n",
    "                               ca_certs=certifi.where())\n",
    "    \n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    for patient in patients:\n",
    "        api = \"https://hiv.biozentrum.unibas.ch/api/data/referenceSequence\"\n",
    "        url = \"/\".join((api, patient))\n",
    "        file_name = folder + \"_\".join((\"hivevo\", \"reference\", patient)) + \".fasta\"\n",
    "        \n",
    "        with http.request('GET', url, preload_content=False) as res, open(file_name, 'wb') as out_file:\n",
    "            shutil.copyfileobj(res, out_file)\n",
    "\n",
    "folder = \"data/references/\"\n",
    "download_hivevo_references(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_region_from_reference(region, reference_path, folder):\n",
    "    \n",
    "    if not os.path.isdir(folder+region):\n",
    "        os.mkdir(folder+region)\n",
    "    \n",
    "    with open(reference_path) as f:\n",
    "        reference_info = json.load(f)\n",
    "    for reg in reference_info['features']:\n",
    "        if reg['name'] == region:\n",
    "            loc = reg['location'][0]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    patient = re.search(r'p[\\d]*', reference_path)[0]\n",
    "    #print(patient)\n",
    "    sequence = reference_info['seq'][loc[0]:loc[1]]\n",
    "    #print(sequence)\n",
    "    res = r'/'+re.search(r'[\\w]*\\.fasta', reference_path)[0].replace(patient, \"_\".join((patient, region)))\n",
    "    \n",
    "    with open(folder+region+res, 'w') as write_file:\n",
    "        write_file.write('>'+reference_info['description'].replace('genomewide', 'region='+region)+'\\n')\n",
    "        write_file.write(sequence)\n",
    "\n",
    "folder = 'data/references/'\n",
    "region = 'V3'\n",
    "ref_path = 'data/references/hivevo_reference_p4.fasta'\n",
    "extracting_region_from_reference(region, ref_path, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sobaka'\n",
    "\"/\".join((folder, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = 'data/references/hivevo_reference_p4.fasta'\n",
    "res = re.search(r'[\\w]*\\.fasta', reference_path)[0]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/references/hivevo_reference_p4.fasta') as file:\n",
    "    json_ref = json.load(file)\n",
    "#json_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haplotype_lst = glob('data/*V3.fasta')\n",
    "reference_lst = glob('data/references/*.fasta')\n",
    "#reference_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame()\n",
    "for path in haplotype_lst:\n",
    "    with open(path, \"r\") as f:\n",
    "        records = json.load(f)\n",
    "    df = pd.DataFrame(records)\n",
    "    df = df.drop(\"description\", axis=1)\n",
    "    df[\"patient\"] = path.split(\"_\")[1]\n",
    "    tdf = pd.concat([tdf, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.groupby(\"patient\").agg({\"days since infection\" : [\"min\", np.median, \"max\", pd.Series.nunique],\n",
    "                            \"patient\": [\"size\"]}).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.columns = [\"days\", \"frequency\", \"name\", \"sequence\", \"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10, 6))\n",
    "sns.stripplot(y=\"patient\", x=\"days\", data=tdf, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will remove p10, because there are too few time points and p7, because it's too different from other samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf[~tdf.patient.isin([\"p7\", \"p10\"])]\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.columns = [\"days\", \"frequency\", \"name\", \"sequence\", \"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, bin_edges = np.histogram(tdf.days.values, 5)\n",
    "bin_edges[0] -= 1\n",
    "bin_edges[-1] += 1\n",
    "tdf[\"bins\"] = np.digitize(tdf.days.values, bin_edges)\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.loc[tdf['patient'] == 'p3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.groupby([\"patient\", \"bins\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf.drop(\"bins\", axis=1)\n",
    "# Will analyse everyone separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\b[\\w\\/]+p4[\\w\\.]+\\b', ' '.join(file_lst))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(file_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[tdf.patient == \"p4\"].groupby('days').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf.reset_index(drop=True)\n",
    "tdf.loc[1, \"sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_json = 'data/hivevo_p4_V3.fasta'\n",
    "\n",
    "with open(path_json) as f:\n",
    "    json_file = json.load(f)\n",
    "json_file[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major haplotypes stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_major_freq(json_file):\n",
    "    dict_days = {}\n",
    "    for obj in json_file:\n",
    "        day = obj['days since infection']\n",
    "        if day in dict_days:\n",
    "            if dict_days[day] < obj['frequency [%]']:\n",
    "                dict_days[day] = obj['frequency [%]']\n",
    "        else:\n",
    "            dict_days[day] = obj['frequency [%]']\n",
    "    return dict_days\n",
    "\n",
    "finding_major_freq(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_major_haplotypes(folder, region, patient):\n",
    "    '''\n",
    "    finding max freq haplotype for each day we know\n",
    "    '''\n",
    "    if not os.path.isdir(folder+'major'):\n",
    "        os.mkdir(folder+'major')\n",
    "    \n",
    "    path_json = folder + \"/\" + \"_\".join(('hivevo', patient, region)) + r'.fasta'\n",
    "    path = path_json.replace(folder, folder+'/major')\n",
    "    \n",
    "    with open(path, \"w\") as fasta_file, open(path_json) as json_f:\n",
    "        json_file = json.load(json_f)\n",
    "        dict_days = finding_major_freq(json_file)\n",
    "        for obj in json_file:\n",
    "            if obj['frequency [%]'] == dict_days[obj['days since infection']]:\n",
    "                line_1 = '>' + obj['name'] + '\\n'\n",
    "                line_2 = obj['sequence'] + '\\n'\n",
    "                lines = [line_1, line_2]\n",
    "                fasta_file.writelines(lines)\n",
    "            else:\n",
    "                continue\n",
    "getting_major_haplotypes('data/','V3','p4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making json to fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2fasta(folder, path_json):\n",
    "    \n",
    "    if not os.path.isdir(folder+'/fasta'):\n",
    "        os.mkdir(folder+'/fasta')\n",
    "        \n",
    "    with open(path_json) as f:\n",
    "        json_file = json.load(f)\n",
    "    \n",
    "    path = path_json.replace('data/', 'data/fasta/')   \n",
    "    with open(path, \"w\") as fasta_file:\n",
    "        i = 0\n",
    "        for obj in json_file:\n",
    "            line_1 = '>' + obj['name'] + str(i) + '\\n'\n",
    "            line_2 = obj['sequence'] + '\\n'\n",
    "            lines = [line_1, line_2]\n",
    "            fasta_file.writelines(lines)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/references/V3/hivevo_reference_p4_V3.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ref2fasta(path_fasta, path_ref_region):\n",
    "    with open(path_fasta, 'a') as fasta, open(path_ref_region) as ref:\n",
    "        for line in ref:\n",
    "            #print(line)\n",
    "            fasta.write(line)\n",
    "            \n",
    "add_ref2fasta('data/major/hivevo_p4_V3.fasta', 'data/references/V3/hivevo_reference_p4_V3.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import ClustalwCommandline\n",
    "clustalw_cline = ClustalwCommandline(\"clustalw\",  align = 'True', infile=\"data/fasta/hivevo_p4_V3.fasta\", output = 'FASTA', outfile = 'data/clustal_output/hivevo_p4_V3.fasta', type = 'DNA')\n",
    "stdout, stderr = clustalw_cline()\n",
    "#print(clustalw_cline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD BE USED https://biopython.org/DIST/docs/api/Bio.Phylo.Applications._Fasttree-module.html\n",
    "\n",
    "!fasttree -nt -gtr < data/clustal_output/hivevo_p4_V3.fasta > data/trees/hivevo_p4_V3.nwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "\n",
    "tree = Phylo.read('data/trees/hivevo_p4_V3.nwk', 'newick')\n",
    "#print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Phylo.to_networkx(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.total_branch_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clade_names_fix(tree):\n",
    "    for idx, clade in enumerate(tree.find_clades()):\n",
    "        if not clade.name:\n",
    "            clade.name=str(idx)\n",
    "\n",
    "Tree = Phylo.read('data/trees/hivevo_p4_V3.nwk', 'newick')\n",
    "clade_names_fix(Tree)\n",
    "G = Phylo.to_networkx(Tree)\n",
    "nx.write_graphml(G, 'data/graphml/hivevo_p4_V3.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml('data/graphml/hivevo_p4_V3.graphml')\n",
    "\n",
    "source = '0'\n",
    "dist_dict = nx.shortest_path_length(G, '0')\n",
    "\n",
    "import operator \n",
    "target = max(dist_dict.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "graph_path = nx.shortest_simple_paths(G, source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path = list(graph_path)\n",
    "lst_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import ClustalwCommandline\n",
    "clustalw_cline = ClustalwCommandline(\"clustalw\",  align = 'True', tree = 'True', infile=\"data/fasta/hivevo_p4_V3.fasta\", output = 'FASTA', outfile = 'data/clustal_output/hivevo_p4_V3.fasta', type = 'DNA')\n",
    "stdout, stderr = clustalw_cline()\n",
    "#print(clustalw_cline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-659e0189b302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpatient_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'hivevo_p4_V3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgetrid_dnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-659e0189b302>\u001b[0m in \u001b[0;36mgetrid_dnd\u001b[0;34m(patient_str)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'''Void func converting .dnd file to .nwk'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_v0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/trees/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpatient_str\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nwk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#get rid of .dnd file\n",
    "\n",
    "def getrid_dnd(patient_str):\n",
    "    '''Void func converting .dnd file to .nwk'''\n",
    "    tmp = '_v0'\n",
    "    while os.path.exists('data/trees/'+patient_str+tmp+'.nwk'):\n",
    "        print(tmp)\n",
    "        tmp = tmp[0:2] + str(int(tmp[-1]) + 1)\n",
    "    with open('data/fasta/'+patient_str+'.dnd') as dnd, open('data/trees/'+patient_str+tmp+'.nwk','w') as nwk:\n",
    "        row = ''\n",
    "        for line in dnd:\n",
    "            row += line.rstrip()\n",
    "        nwk.write(row)\n",
    "\n",
    "patient_str = 'hivevo_p4_V3'\n",
    "getrid_dnd(patient_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Tree = Phylo.read('data/trees/hivevo_p4_V3_v0.nwk', 'newick')\n",
    "#print(Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_names_fix(Tree)\n",
    "G = Phylo.to_networkx(Tree)\n",
    "nx.write_graphml(G, 'data/graphml/hivevo_p4_V3.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_nodes = list(G.nodes)\n",
    "lst_edges = list(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml('data/graphml/hivevo_p4_V3.graphml')\n",
    "\n",
    "source = lst_nodes[0]\n",
    "dist_dict = nx.shortest_path_length(G, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = max(dist_dict.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "graph_path = nx.shortest_simple_paths(G, source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path = list(graph_path)\n",
    "lst_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
